{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Exchange is an information powerhouse, built on the power of crowdsourcing. It has 105 different topics and each topic has a library of questions which have been asked and answered by knowledgeable members of the StackExchange community. The topics are as diverse as travel, cooking, programming, engineering and photography.\n",
    "\n",
    "stackoverflow\n",
    "\n",
    "We have hand-picked ten different topics (such as Electronics, Mathematics, Photography etc.) from Stack Exchange, and we provide you with a set of questions from these topics.\n",
    "\n",
    "Given a question and an excerpt, your task is to identify which among the 10 topics it belongs to.\n",
    "\n",
    "Getting started with text classification\n",
    "\n",
    "For those getting started with this fascinating domain of text classification, here's a wonderful Youtube video of Professor Dan Jurafsky from Stanford, explaining the Naive Bayes classification algorithm, which you could consider using as a starting point.\n",
    "\n",
    "\n",
    "Input Format \n",
    "The first line will be an integer N. N lines follow each line being a valid JSON object. The following fields of raw data are given in json\n",
    "\n",
    "question (string) : The text in the title of the question.\n",
    "excerpt (string) : Excerpt of the question body.\n",
    "topic (string) : The topic under which the question was posted.\n",
    "The input for the program has all the fields but topic which you have to predict as the answer.\n",
    "\n",
    "Constraints \n",
    "1 <= N <= 22000 \n",
    "topic is of ascii format \n",
    "question is of UTF-8 format \n",
    "excerpt is of UTF-8 format\n",
    "\n",
    "Output Format \n",
    "For each question that is given as a JSON object, output the topic of the question as predicted by your model separated by newlines.\n",
    "\n",
    "The training file is available here. It is also present in the current directory in which your code is executed.\n",
    "\n",
    "Sample Input\n",
    "\n",
    "12345\n",
    "json_object\n",
    "json_object\n",
    "json_object\n",
    ".\n",
    ".\n",
    ".\n",
    "json_object\n",
    "Sample Output\n",
    "\n",
    "electronics\n",
    "security\n",
    "photo\n",
    ".\n",
    ".\n",
    ".\n",
    "mathematica\n",
    "Sample testcases can be downloaded here for offline training. When you submit your solution to us, you can assume that the training file can be accessed by reading \"training.json\" which will be placed in the same folder as the one in which your program is being executed.\n",
    "\n",
    "Scoring\n",
    "\n",
    "While the contest is going on, the score shown to you will be on the basis of the Sample Test file. The final score will be based on the Hidden Testcase only and there will be no weightage for your score on the Sample Test.\n",
    "\n",
    "Score = MaxScore for the test case * (C/T) \n",
    "Where C = Number of topics identified correctly and \n",
    "T = total number of test JSONs in the input file.## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "count=0\n",
    "topic=[]\n",
    "question=[]\n",
    "excerpt=[]\n",
    "def words(text):\n",
    "    return re.findall(r'(?:[a-zA-Z]+[a-zA-Z\\'\\-]?[a-zA-Z]|[a-zA-Z]+)',text)\n",
    "\n",
    "with open('training.json', 'r') as f:\n",
    "    for line in f:\n",
    "        count+=1\n",
    "        if count==1:\n",
    "            continue\n",
    "        post = json.loads(line)\n",
    "        topic.append(post[\"topic\"])\n",
    "        abc=post[\"question\"]+\"\\r\\n\"+post[\"excerpt\"]\n",
    "        sen=\"\".join(word for word in words(abc))\n",
    "        excerpt.append(abc)\n",
    "\n",
    "\n",
    "x_train=np.array(excerpt)\n",
    "\n",
    "y_train=topic\n",
    "\n",
    "txt_clf=Pipeline([('vect',CountVectorizer()),\n",
    "                  ('tfidf',TfidfTransformer()),\n",
    "                  ('clf',LinearSVC())])\n",
    "txt_clf.fit(x_train, y_train)\n",
    "_test=[]\n",
    "for i in range(int(input())):\n",
    "    h=json.loads(input())\n",
    "    _test.append(h['question']+\"\\r\\n\"+h['excerpt'])\n",
    "predicted=txt_clf.predict(_test)\n",
    "for i in predicted:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
