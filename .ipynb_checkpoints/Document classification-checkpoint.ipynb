{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been given a stack of documents that have already been processed and some that have not. Your task is to classify these documents into one of eight categories: [1,2,3,...8]. You look at the specifications on what a document must contain and are baffled by the jargon. However, you notice that you already have a large amount of documents which have already been correctly categorize (training data). You decide to use Machine Learning on this data in order to categorize the uncategorized documents.\n",
    "\n",
    "Training Data\n",
    "\n",
    "In order to figure out what category each document should fall under you will base it on the categories of the documents in the \"trainingdata.txt\" file. This file will be included with your program at runtime and will be named \"trainingdata.txt\".\n",
    "\n",
    "The file is formatted as follows:\n",
    "\n",
    "The first line contains the number of lines that will follow.\n",
    "\n",
    "Each following line will contain a number (1-8), which is the category number. The number will be followed by a space then some space seperated words which is the processed document.\n",
    "\n",
    "Input\n",
    "\n",
    "The first line in the input file will contain T the number of documents. T lines will follow each containing a series of space seperated words which represents the processed document.\n",
    "\n",
    "Output\n",
    "\n",
    "For each document output a number between 1-8 which you believe this document should be categorized as.\n",
    "\n",
    "Sample Input\n",
    "\n",
    "3 \n",
    "This is a document \n",
    "this is another document \n",
    "documents are seperated by newlines\n",
    "\n",
    "Sample Output\n",
    "\n",
    "1 \n",
    "4 \n",
    "8\n",
    "\n",
    "Scoring\n",
    "\n",
    "Your score for this challenge will be 100* (#correctly categorized - #incorrectly categorized)/(T).# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"trainingdata.txt\",\"r+\")\n",
    "x=[]\n",
    "y=[]\n",
    "n=int(file1.readline())\n",
    "#print(type(n))\n",
    "count=0\n",
    "for i in range(n):\n",
    "    line=file1.readline().rstrip()\n",
    "    l=line.find(\" \")\n",
    "    y.append(int(line[:l]))\n",
    "    x.append(line[l:])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(x)\n",
    "count_vect.vocabulary_.get(u'algorithm')\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y)\n",
    "a=int(input())\n",
    "#print(x[1],type(x[1]))\n",
    "docx=[]\n",
    "for i in range(a):\n",
    "    z=input()\n",
    "    docx.append(str(z))\n",
    "X_new_counts = count_vect.transform(docx)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for i in range(len(predicted)):\n",
    "    print(predicted[i])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"trainingdata.txt\",\"r+\")\n",
    "x=[]\n",
    "y=[]\n",
    "n=int(file1.readline())\n",
    "#print(n)\n",
    "count=0\n",
    "for i in range(n):\n",
    "    line=file1.readline().rstrip()\n",
    "    l=line.find(\" \")\n",
    "    y.append(int(line[:l]))\n",
    "    x.append(line[l:])\n",
    "#print(len(x),len(y))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(x)\n",
    "#count_vect.vocabulary_.get(u'algorithm')\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "#X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#clf = MultinomialNB().fit(X_train_tfidf, y)\n",
    "from sklearn.svm import LinearSVC\n",
    "#clf=LinearSVC()\n",
    "#clf.fit(X_train_tfidf, y)\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-6, random_state=42,\n",
    "                                 max_iter=400, )\n",
    "clf.fit(X_train_counts, y)\n",
    "\n",
    "a=int(input())\n",
    "#print(x[1],type(x[1]))\n",
    "file1.close()\n",
    "docx=[]\n",
    "for i in range(a):\n",
    "    z=input()\n",
    "    docx.append(str(z))\n",
    "X_new_counts = count_vect.transform(docx)\n",
    "#X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_counts)\n",
    "for i in range(len(predicted)):\n",
    "    print(predicted[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
